{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5551197-4f1b-4341-87e2-6ac529297e5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc50aa5-62a3-4c74-a66b-d3d1ceb6c9e2",
   "metadata": {},
   "source": [
    "<h3> Загрузка библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee14abb5-ab02-498a-97c4-06e006266cca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46805e0c-6abf-4220-aeb5-1720cba916bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scripts.load_and_save import (get_dcm_info, get_dcm_vol, vox_size2affine,\n",
    "                                   save_vol_as_nii, load_sample_data)\n",
    "from scripts.load_and_save import load_nii_vol, save_vol_as_nii, load_sample_data\n",
    "\n",
    "from ml.models.unet3d import U_Net\n",
    "from ml.models.rog import ROG\n",
    "from ml.models.unet_deepsup import U_Net_DeepSup\n",
    "\n",
    "from ml.utils import get_total_params, save_model, load_pretrainned\n",
    "from ml.dataset import preprocess_dataset, HVB_Dataset, norm_vol\n",
    "from ml.trainer import Trainer\n",
    "from ml.losses import ExponentialLogarithmicLoss, WeightedExpBCE, TverskyLoss, IOU_Metric, MultyscaleLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6af17a1-a09a-44b0-b96f-0e06faa4ee99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd09a43-736a-45a9-924c-abcf307c6a5d",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3> Создание экзепляра класса датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a82a75f-5ad6-4b48-8258-9eb80151242b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/msst/Documents/medtech/brain_seg_dataset/P12_CTA(no_brain) P12_CTA(no_brain)\n",
      "/home/msst/Documents/medtech/brain_seg_dataset/CT_S5020_uint16 CT_S5020_uint16\n",
      "/home/msst/Documents/medtech/brain_seg_dataset/P62_CTA(no_brain) P62_CTA(no_brain)\n"
     ]
    }
   ],
   "source": [
    "train_dataset_settings = {\n",
    "    \"data_dir\" : \"/home/msst/Documents/medtech/brain_seg_dataset\",\n",
    "    \"patch_shape\" : (64, 64, 64),\n",
    "    \"number_of_patches\" : 256,\n",
    "    \"mode\": \"train\",\n",
    "    \"RAM_samples\" : True \n",
    "}\n",
    "patch_data_df, sample_data_df = preprocess_dataset(train_dataset_settings)\n",
    "train_dataset = HVB_Dataset(train_dataset_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9fa5aa8-6710-4a16-96e4-2b0274fde4d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_dataset_settings = {\n",
    "    \"data_dir\" : \"/home/msst/Documents/medtech/brain_seg_dataset\",\n",
    "    \"patch_shape\" : (256, 256, 128),\n",
    "    \"mode\": \"eval\",\n",
    "    \"RAM_samples\" : train_dataset_settings[\"RAM_samples\"] \n",
    "}\n",
    "val_dataset = HVB_Dataset(val_dataset_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f5be7f5-8984-4bf0-bebf-7c7adc79cb09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/msst/Documents/medtech/brain_seg_dataset_test/P35_CTA 0.625mm(no_seg) P35_CTA 0.625mm(no_seg)\n",
      "/home/msst/Documents/medtech/brain_seg_dataset_test/P70_CTA 0.625mm(no_seg) P70_CTA 0.625mm(no_seg)\n",
      "/home/msst/Documents/medtech/brain_seg_dataset_test/P28_CTA_(0.42, 0.42, 0.3)(no_seg) P28_CTA_(0.42, 0.42, 0.3)(no_seg)\n"
     ]
    }
   ],
   "source": [
    "test_dataset_settings = {\n",
    "    \"data_dir\" : \"/home/msst/Documents/medtech/brain_seg_dataset_test\",\n",
    "    \"patch_shape\" : (256, 256, 128),\n",
    "    \"mode\": \"eval\",\n",
    "    \"number_of_patches\" : 0,\n",
    "    \"RAM_samples\" : False\n",
    "}\n",
    "preprocess_dataset(test_dataset_settings)\n",
    "test_dataset = HVB_Dataset(test_dataset_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d96b819f-040a-40e2-aa94-0c080a5308f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader_params = {\"batch_size\": 16,\n",
    "                 \"shuffle\": True,\n",
    "                 \"num_workers\": 6\n",
    "                }\n",
    "\n",
    "val_loader_params = {\"batch_size\": 1,\n",
    "                     \"shuffle\": False,\n",
    "                     \"num_workers\": 6\n",
    "                    }\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, **train_loader_params)\n",
    "val_dataloader = DataLoader(val_dataset, **val_loader_params)\n",
    "test_dataloader = DataLoader(test_dataset, **val_loader_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8fe74871-e1dc-4594-a818-48c6177cfb2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(val_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95377fe-0b9c-4405-8bed-d99b03289a07",
   "metadata": {},
   "source": [
    "<h3> Создание экземпляра модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87601130-26ed-46d1-be07-9f40b3c2b4f8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#rog_params = {\n",
    "#    'classes': 1,\n",
    "#    'modalities': 1,\n",
    "#    'strides': [[2, 2, 1], [2, 2, 1], [2, 2, 2]],\n",
    "#}\n",
    "#model = ROG(rog_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63a09e15-308b-486d-b7ee-76c35ec5f7e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model = U_Net()\n",
    "class swish(nn.Module):\n",
    "    def forward(self, input_tensor):\n",
    "        return input_tensor * torch.sigmoid(input_tensor)\n",
    "\n",
    "#act_fn: nn.PReLU(inplace=True), nn.ReLU(inplace=True), swish\n",
    "model = U_Net_DeepSup(channel_coef=16, act_fn=swish())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5eecf77-8a4a-4559-a1b9-bd86ca6be108",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 6477875\n"
     ]
    }
   ],
   "source": [
    "print('Number of parameters: {}'.format(get_total_params(model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36d7c0f2-d2c2-47c5-99dc-f4ac60255ba3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "\n",
    "\n",
    "class LitModel(L.LightningModule):\n",
    "    def __init__(self, torch_model, loss_fn, learning_rate):\n",
    "        super().__init__()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model = torch_model\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        head_batch = batch['head_patch'].to(self.device)\n",
    "        vessels_batch = batch['vessels_patch'].to(self.device)\n",
    "    \n",
    "        outputs = self.model.forward(head_batch)\n",
    "        loss = self.loss_fn(vessels_batch, outputs)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return(loss)\n",
    "    \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "\n",
    "#loss_fn = MultyscaleLoss(ExponentialLogarithmicLoss(gamma_tversky = 0.5, gamma_bce = 0.5, lamb=0.01,\n",
    "#                                                    freq = 0.001, tversky_alfa=0.5))\n",
    "#lightning_model = LitModel(model, loss_fn, 0.01)\n",
    "#trainer = L.Trainer(accelerator='gpu', auto_lr_find=True)\n",
    "#trainer.tune(lightning_model, train_dataloaders=train_dataloader)\n",
    "#print(\"predicted best lr:\", lightning_model.learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05150b88-328e-410d-9ae1-e566f6fbe9ce",
   "metadata": {},
   "source": [
    "<h3> Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d99a5d0-539f-4543-8b12-ad139e4224f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#loss_fn = nn.BCELoss(reduction='mean')\n",
    "\n",
    "#loss_fn = ExponentialLogarithmicLoss(gamma_tversky = 1, gamma_bce = 1, lamb=1, freq = 0.001)\n",
    "#loss_fn.weighted_bce_loss.bce_weight = 1\n",
    "\n",
    "#print(loss_fn.weighted_bce_loss.bce_weight)\n",
    "\n",
    "#loss_fn = WeightedExpBCE(0.5)\n",
    "#loss_fn = TverskyLoss(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdc41e48-ac6e-4b6d-91bf-a37f0b89a091",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#l = WeightedExpBCE(0.5)\n",
    "#l.set_bce_weight(0.001)\n",
    "#loss_fn = MultyscaleLoss(l)\n",
    "\n",
    "#loss_fn = MultyscaleLoss(TverskyLoss(0.75))\n",
    "\n",
    "loss_fn = MultyscaleLoss(ExponentialLogarithmicLoss(gamma_tversky = 1, gamma_bce = 1, lamb=0.9,\n",
    "                                                    freq = 0.001, tversky_alfa=0.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db3f01a2-a9a6-418c-9f24-d417ed431483",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metric_fn = IOU_Metric()\n",
    "\n",
    "trainer_config = {\n",
    "    'n_epochs': 100,\n",
    "    \"loss\" : loss_fn,\n",
    "    \"metric\" : metric_fn,\n",
    "    'device' : device,\n",
    "    \"optimizer_fn\" : lambda model: torch.optim.ASGD(model.parameters(), lr=0.25),\n",
    "    \"sheduler_fn\": lambda optimizer: StepLR(optimizer, step_size=5, gamma=0.5) \n",
    "}\n",
    "trainer = Trainer(trainer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55c90269-3eec-4016-aafa-9d25481e67a4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/48 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repo/MSRepo/VesselSegmentation/ml/trainer.py:45\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloader, val_dataloader)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epochs):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 45\u001b[0m     train_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28mprint\u001b[39m(train_info)\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(train_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/repo/MSRepo/VesselSegmentation/ml/trainer.py:64\u001b[0m, in \u001b[0;36mTrainer.train_epoch\u001b[0;34m(self, train_dataloader)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[1;32m     63\u001b[0m     train_dataloader \u001b[38;5;241m=\u001b[39m tqdm(train_dataloader)\n\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[1;32m     65\u001b[0m     head_batch \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhead_patch\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     66\u001b[0m     vessels_batch \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvessels_patch\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1295\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1297\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/queues.py:107\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    106\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/usr/lib/python3.8/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = trainer.fit(model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924a559f-05e7-4e5c-a8ad-81d2c5237221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46187a77-c050-47fd-b824-374e8f8bd133",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"UnetMSS16_logTversky_100\"\n",
    "#trainer.save(\"/home/msst/repo/MSRepo/VesselSegmentation/saved_models/\" + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7822c6f4-2f6f-431a-8ef8-eeebe530daed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"/home/msst/repo/MSRepo/VesselSegmentation/saved_models/\" + model_name)[\"model_state_dict\"])\n",
    "trainer.model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5283b921-c9a4-43bc-a8c6-82ade78251a7",
   "metadata": {},
   "source": [
    "<h3> Сегментация с помощью обученной модели\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2031bf17-a129-4870-8cf3-142477b598fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 False1\n",
      " False\n",
      "1 False\n",
      "/home/msst/Documents/medtech/brain_seg_dataset_test/P70_CTA 0.625mm(no_seg) P70_CTA 0.625mm(no_seg)\n",
      "2\n",
      "/home/msst/Documents/medtech/brain_seg_dataset_test/P35_CTA 0.625mm(no_seg) P35_CTA 0.625mm(no_seg)\n",
      "2\n",
      "### P35_CTA 0.625mm(no_seg) ###\n",
      "/home/msst/Documents/medtech/brain_seg_dataset_test/P28_CTA_(0.42, 0.42, 0.3)(no_seg) P28_CTA_(0.42, 0.42, 0.3)(no_seg)\n",
      "2\n",
      "metric: tensor([8.0569e-05]) sum/sum_GT: tensor(0.0005)\n",
      "### P70_CTA 0.625mm(no_seg) ###\n",
      "metric: tensor([4.5899e-05]) sum/sum_GT: tensor(0.0002)\n",
      "### P28_CTA_(0.42, 0.42, 0.3)(no_seg) ###\n",
      "metric: tensor([0.0001]) sum/sum_GT: tensor(2.2750e-05)\n"
     ]
    }
   ],
   "source": [
    "#patch_shape = (256, 256, 128)\n",
    "data_loader = test_dataloader#val_dataloader\n",
    "\n",
    "patch_shape = data_loader.dataset.patch_shape\n",
    "for batch in data_loader:\n",
    "    head_batch = batch['head']\n",
    "    vessels_batch = batch['vessels']\n",
    "    affine = batch['affine'][0]\n",
    "    sample_name = batch['sample_name'][0]\n",
    "    print(\"###\", sample_name, \"###\")\n",
    "    \n",
    "    head_seg = trainer.predict(head_batch, patch_shape)\n",
    "    metric = trainer.metric_fn(head_seg, vessels_batch)\n",
    "    \n",
    "    print('metric:', metric, \"sum/sum_GT:\", head_seg.sum()/vessels_batch.sum())\n",
    "    \n",
    "    vessels_seg = head_seg[0, 0]\n",
    "    data_dir = \"seg_data/\" + model_name\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.mkdir(data_dir)\n",
    "\n",
    "    path_to_save_vessels = data_dir + '/' + sample_name + '.nii.gz'\n",
    "    save_vol_as_nii(vessels_seg, affine, path_to_save_vessels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0965ac98-57fd-4d93-a289-c92f2daeb9a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(head_seg.sum())\n",
    "vessels_seg = head_seg[0, 0]\n",
    "print(vessels_seg.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f104da62-9d7a-4c44-828a-ee23f496c74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"seg_data/P12_CTA\"\n",
    "if not os.path.exists(data_dir):\n",
    "    os.mkdir(data_dir)\n",
    "\n",
    "\n",
    "path_to_save_vessels = data_dir + '/' + model_name + '_2.nii.gz'\n",
    "save_vol_as_nii(vessels_seg, affine, path_to_save_vessels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fee0a1-af4c-4696-b11e-8295e52ad1c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c943353-2395-4856-91e1-60bee19dd3c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9281f2d-49a0-443b-b2a8-a1cbb8a1127f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
