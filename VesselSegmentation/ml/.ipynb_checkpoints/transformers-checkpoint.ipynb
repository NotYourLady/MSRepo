{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8c87780-f1e8-4a7f-9fb4-415663445f9d",
   "metadata": {},
   "source": [
    "<h2>Import Libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd295df6-9964-4f51-8883-355728e0ea18",
   "metadata": {},
   "source": [
    "<h2> Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cc4f56-115b-404b-b9a8-e33a8d56eb7a",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2> Train Test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6ba11e-da13-48ce-88a4-82e6bb3542bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2> Creating datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92d44b39-9c57-44b1-bf36-ddc2df4e58ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42abe5fc-7951-41d6-a045-9d302cb0c55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "from dataset import *\n",
    "from model import MyClassificator, BertForClassification, TransformerBasedModel\n",
    "from trainer import Trainer, test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2a1359d-ff47-4067-bd4e-04043d73b26e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PATH = \"datasets/\"\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 128\n",
    "EMBEDDING_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4e8fb1f-c141-4342-b39a-55247c70c35b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(os.path.join(PATH, \"train.csv\"))\n",
    "test_data = pd.read_csv(os.path.join(PATH, \"test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9642cfab-78ee-4127-8406-2185281819c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_name</th>\n",
       "      <th>target</th>\n",
       "      <th>movie_description</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Furies</td>\n",
       "      <td>0</td>\n",
       "      <td>Three furious vigilantes unite to take down a ...</td>\n",
       "      <td>133529636342330622371894152500993949030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RRR</td>\n",
       "      <td>0</td>\n",
       "      <td>The story of freedom fighters Komaram Bheem an...</td>\n",
       "      <td>133529660110779376651195430564179049830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John Wick</td>\n",
       "      <td>0</td>\n",
       "      <td>Legendary assassin John Wick (Keanu Reeves) re...</td>\n",
       "      <td>133529680710101630359923204885606137190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>John Wick: Chapter 3 -- Parabellum</td>\n",
       "      <td>0</td>\n",
       "      <td>After gunning down a member of the High Table ...</td>\n",
       "      <td>133529687048354631501070212369122164070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Top Gun: Maverick</td>\n",
       "      <td>0</td>\n",
       "      <td>After more than thirty years of service as one...</td>\n",
       "      <td>133529699724860633783364227336154217830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           movie_name  target  \\\n",
       "0                              Furies       0   \n",
       "1                                 RRR       0   \n",
       "2                           John Wick       0   \n",
       "3  John Wick: Chapter 3 -- Parabellum       0   \n",
       "4                   Top Gun: Maverick       0   \n",
       "\n",
       "                                   movie_description  \\\n",
       "0  Three furious vigilantes unite to take down a ...   \n",
       "1  The story of freedom fighters Komaram Bheem an...   \n",
       "2  Legendary assassin John Wick (Keanu Reeves) re...   \n",
       "3  After gunning down a member of the High Table ...   \n",
       "4  After more than thirty years of service as one...   \n",
       "\n",
       "                                        id  \n",
       "0  133529636342330622371894152500993949030  \n",
       "1  133529660110779376651195430564179049830  \n",
       "2  133529680710101630359923204885606137190  \n",
       "3  133529687048354631501070212369122164070  \n",
       "4  133529699724860633783364227336154217830  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "212923e9-ad75-45a6-9b3a-48d80541a45a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.000000e+00\n",
      "1       2.376845e-59\n",
      "2       4.436777e-59\n",
      "3       5.070602e-59\n",
      "4       6.338253e-59\n",
      "            ...     \n",
      "8045    6.524915e-56\n",
      "8046    6.526103e-56\n",
      "8047    6.526658e-56\n",
      "8048    6.527291e-56\n",
      "8049    6.527846e-56\n",
      "Name: id, Length: 8050, dtype: float128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "8045    5\n",
       "8046    5\n",
       "8047    5\n",
       "8048    5\n",
       "8049    5\n",
       "Name: target, Length: 8050, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['id'] = train_data['id'].astype(np.float128)\n",
    "print(train_data['id'])\n",
    "m = train_data['id'].min()\n",
    "train_data['id'] = (train_data['id'] - m)/(10.0**30)\n",
    "train_data['id']\n",
    "train_data[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "461f9b07-25be-4188-9ad3-56795cb541fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#plt.hist([t for t in train_data.target], bins=20);\n",
    "#plt.hist([len(s) for s in train_data.movie_description], bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1934fc1-23c1-4bb8-97a2-019af8d0b191",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_split, val_split = train_test_split(train_data, train_frac=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04e950b9-cf37-475b-899d-3a008c0b254c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained(\n",
    "    \"distilbert-base-uncased\", truncation=True, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e051fe6-6988-4ecf-9dd9-6d0be6382c3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34de8b54-47de-4d11-98fa-db20adba9cb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = RottenTomatoesDataset(train_split, tokenizer, MAX_LEN)\n",
    "val_dataset = RottenTomatoesDataset(val_split, tokenizer, MAX_LEN)\n",
    "test_dataset = RottenTomatoesDataset(test_data, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c97d4a4f-5f7f-47fd-9087-fa49e65a90ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_params = {\"batch_size\": BATCH_SIZE,\n",
    "                \"shuffle\": True,\n",
    "                \"num_workers\": 10\n",
    "                }\n",
    "\n",
    "test_params = {\"batch_size\": BATCH_SIZE,\n",
    "               \"shuffle\": False,\n",
    "               \"num_workers\": 10\n",
    "               }\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, **train_params)\n",
    "val_dataloader = DataLoader(val_dataset, **test_params)\n",
    "test_dataloader = DataLoader(test_dataset, **test_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9958549e-0c8f-4471-859d-bcbdf2c90fa4",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2> Loading pretrained model from Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43a6a24a-4bca-468a-b754-3e4c32db19fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"num_classes\": 6,\n",
    "    \"dropout_rate\": 0.0,\n",
    "    \"embedding_size\": EMBEDDING_SIZE\n",
    "}\n",
    "model = BertForClassification(\n",
    "    \"distilbert-base-uncased\",\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fad0dbbc-d976-4db4-9c24-500685161e8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "n_unfreezed = 0\n",
    "for name, p in model.named_parameters():\n",
    "    #print(name)\n",
    "    if (\n",
    "        name.startswith(\"classifier\") or\n",
    "        name.startswith(\"bert.transformer.layer.5\") \n",
    "        ):\n",
    "        \n",
    "        p.requires_grad = True\n",
    "        n_unfreezed += 1\n",
    "    else:\n",
    "        p.requires_grad = False\n",
    "\n",
    "print(n_unfreezed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe1cc5b4-de82-486e-97ca-1d967da6e11b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test_model(model, train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d47802-7718-4614-8648-88b7c8d17403",
   "metadata": {},
   "source": [
    "<h2> Creating Trainer object and fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d977507f-927d-489e-85fe-974742bf4471",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4638d4753b244fb085ebf3a6d9ae44c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c03ec2c40434813bccf4d96fbcd1ed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6650124192237854\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b01ecb21744423395dbbe093a57eefe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "957e632c7f204b98a5bc6fc64c0f6575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6488833427429199\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForClassification(\n",
       "  (bert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier_def): Sequential(\n",
       "    (0): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Dropout(p=0.0, inplace=False)\n",
       "    (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.05)\n",
       "    (4): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): Dropout(p=0.0, inplace=False)\n",
       "    (6): Linear(in_features=768, out_features=6, bias=True)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Dropout(p=0.0, inplace=False)\n",
       "    (2): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.05)\n",
       "    (4): BatchNorm1d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): Dropout(p=0.0, inplace=False)\n",
       "    (6): Linear(in_features=1536, out_features=768, bias=True)\n",
       "    (7): LeakyReLU(negative_slope=0.05)\n",
       "    (8): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): Dropout(p=0.0, inplace=False)\n",
       "    (10): Linear(in_features=768, out_features=6, bias=True)\n",
       "  )\n",
       "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_config = {\n",
    "    \"lr\": 3e-4,\n",
    "    \"n_epochs\": 2,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "}\n",
    "\n",
    "t = Trainer(trainer_config)\n",
    "t.fit(\n",
    "    model,\n",
    "    train_dataloader,\n",
    "    val_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be706a25-2109-42ea-b547-a525a206e97b",
   "metadata": {},
   "source": [
    "<h2> Save and Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f03d9d-6c05-47e6-abaa-61971dfae20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.save(\"baseline_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42906a85-7d6b-4fae-80dc-8bc89383566b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t = Trainer.load(\"baseline_model.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc1e0a3-e8a5-4271-af78-6d502beff6c9",
   "metadata": {},
   "source": [
    "<h2> Create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e995311-af23-4597-87b9-86e7b49ee5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = t.predict(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27da3622-3b32-4fa6-9326-ffcbe90a2b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>133529667241314002934985813983134580070</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>133529693386607632642217219852638190950</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133529737754378640630246272237250379110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>133529756769137644053687294687798459750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>133529828866765532034234504812793265510</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        id  target\n",
       "0  133529667241314002934985813983134580070       2\n",
       "1  133529693386607632642217219852638190950       1\n",
       "2  133529737754378640630246272237250379110       1\n",
       "3  133529756769137644053687294687798459750       1\n",
       "4  133529828866765532034234504812793265510       1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission = pd.read_csv(os.path.join(PATH, \"sample_submission.csv\"))\n",
    "sample_submission[\"target\"] = predictions\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "915044b8-6324-4805-9b14-9172ddb1eac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e6ce04-b519-45f0-ae2b-b4a39bf0df5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6fa9d78d-9c38-430e-98a1-fe55d7f5f15d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "n_unfreezed = 0\n",
    "for name, p in model.named_parameters():\n",
    "    #print(name)\n",
    "    if (\n",
    "        name.startswith(\"classifier\") or\n",
    "        name.startswith(\"bert.transformer.layer.5\") or\n",
    "        name.startswith(\"bert.pooler\") or\n",
    "        name.startswith(\"bert.encoder.layer.11\")\n",
    "        ):\n",
    "        \n",
    "        #p.requires_grad = True\n",
    "        #n_unfreezed += 1\n",
    "        1\n",
    "    else:\n",
    "        1\n",
    "        #p.requires_grad = False\n",
    "\n",
    "print(n_unfreezed)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "65393c1d-4002-41cf-a838-0b84b0e2e548",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config = {\n",
    "#    \"vocab_size\" : len(tokenizer.vocab),\n",
    "#    \"data_length\": MAX_LEN,\n",
    "#    \"num_classes\": 6,\n",
    "#    \"dropout_rate\": 0.0,\n",
    "#    \"embedding_size\": EMBEDDING_SIZE,\n",
    "#    'transformer_size': 3,\n",
    "#    \"pretrained_embeddings\" : None#  w2v_embedding #None# \n",
    "#}\n",
    "#model = TransformerBasedModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "58c38c4d-e8e7-4f6d-9002-85afc43f290d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "id2label = {0: 0, 1: 1, 2:2, 3:3,4:4,5:5}\n",
    "label2id = {0: 0, 1: 1, 2:2, 3:3,4:4,5:5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6592cfc7-0490-4967-9c12-d65d5d2430fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", num_labels=6, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a3b8f7f-07ab-4b93-a2f4-fe3bd5f1d42f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#config = {\n",
    "#    \"vocab_size\" : len(tokenizer.vocab),\n",
    "#    \"labels_num\" : 6,\n",
    "#    \"max_text_len\" : MAX_LEN,\n",
    "#    \"embedding_size\" : 128,\n",
    "#    \"n_layers\" : 3,\n",
    "#    \"pretrained_embeddings\" : None#w2v_embedding\n",
    "#}    \n",
    "#model = MyClassificator(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad3f8a3-e32e-4c55-acf0-7b7f6facfe09",
   "metadata": {},
   "source": [
    "<h2>Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a745a30-983a-4f1a-9778-d500096769d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataset import get_data_for_w2v\n",
    "dataset_for_word_to_vec = get_data_for_w2v(train_data, MAX_LEN, tokenizer)\n",
    "dataset_for_word_to_vec_2 = get_data_for_w2v(test_data, MAX_LEN, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "85a7eb5c-6496-41c8-bf80-ff917a7f06e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10734\n"
     ]
    }
   ],
   "source": [
    "dataset_for_word_to_vec_full = dataset_for_word_to_vec + dataset_for_word_to_vec_2\n",
    "print(len(dataset_for_word_to_vec_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14cd519b-3eb8-492e-a139-17cc8a301bb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "word2vec = gensim.models.Word2Vec(sentences=dataset_for_word_to_vec_full, vector_size=EMBEDDING_SIZE,\n",
    "                                  window=5, min_count=0, workers=16,\n",
    "                                  sg=1, epochs=10, null_word=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dd3c22-c5df-4be3-800f-57bc2c15112a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "740f90e4-c222-4e7e-bc0a-9f83aed58bb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "w2v_vectors = np.zeros((len(tokenizer.vocab), EMBEDDING_SIZE)).astype(np.float32)\n",
    "for new_idx, w2v_idx in enumerate(word2vec.wv.index_to_key):\n",
    "    w2v_vectors[w2v_idx] = word2vec.wv[new_idx]\n",
    "w2v_vectors = torch.tensor(w2v_vectors)    \n",
    "#w2v_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5edc452f-00ac-4822-ab15-3b8eba15608c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "w2v_embedding = torch.nn.Embedding(w2v_vectors.shape[0], w2v_vectors.shape[1], padding_idx=0)\n",
    "w2v_embedding = w2v_embedding.from_pretrained(w2v_vectors, freeze=True, padding_idx=0)\n",
    "#w2v_embedding.weight"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
