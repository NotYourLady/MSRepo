{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b562ff24-6569-4c01-bda9-0087f7495356",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e16d0ac-0578-4e02-9a3f-ed8a60dc2a8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from LiquidNet import LiquidNet, LiquidNetBlock, conv_block, bottle_neck_connection\n",
    "#from LiquidNet_configs.second_config import get_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8b9b2d-e7a8-4377-a62a-e4fa8a4748cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dilated_feature_extractor(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, bias=True,\n",
    "                 act_fn=nn.ReLU(inplace=True), padding_mode='replicate'):\n",
    "        super(dilated_feature_extractor, self).__init__()\n",
    "        # self.conv11 = nn.Sequential(\n",
    "        #     nn.Conv3d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size,\n",
    "        #               stride=stride, padding=padding, bias=bias),\n",
    "        #     #nn.BatchNorm3d(num_features=out_channels),\n",
    "        #     nn.InstanceNorm3d(out_channels, affine=True),\n",
    "        #     act_fn,\n",
    "        #     nn.Conv3d(in_channels=out_channels, out_channels=out_channels, kernel_size=kernel_size,\n",
    "        #               stride=stride, padding=padding, bias=bias),\n",
    "        #     #nn.BatchNorm3d(num_features=out_channels),\n",
    "        #     nn.InstanceNorm3d(out_channels, affine=True),\n",
    "        #     act_fn\n",
    "        # )\n",
    "        self.conv1x1 = nn.Conv3d(in_channels=in_channels, out_channels=out_channels, kernel_size=1,\n",
    "                      stride=1, padding=0, bias=bias, padding_mode=padding_mode)\n",
    "        self.dconv1 = nn.Conv3d(in_channels=in_channels, out_channels=out_channels, kernel_size=3,\n",
    "                      stride=1, padding=1, dilation=1, bias=bias, padding_mode=padding_mode)\n",
    "        self.dconv2 = nn.Conv3d(in_channels=in_channels, out_channels=out_channels, kernel_size=3,\n",
    "                      stride=1, padding=2, dilation=2, bias=bias, padding_mode=padding_mode)\n",
    "        self.dconv3 = nn.Conv3d(in_channels=in_channels, out_channels=out_channels, kernel_size=3,\n",
    "                      stride=1, padding=3, dilation=3, bias=bias, padding_mode=padding_mode)\n",
    "        self.dconv4 = nn.Conv3d(in_channels=in_channels, out_channels=out_channels, kernel_size=3,\n",
    "                      stride=1, padding=4, dilation=4, bias=bias, padding_mode=padding_mode)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv_outs = []\n",
    "        conv_outs.append(self.conv1x1(x))\n",
    "        conv_outs.append(self.dconv1(x))\n",
    "        conv_outs.append(self.conv1x1(x))\n",
    "        conv_outs.append(self.conv1x1(x))\n",
    "        conv_outs.append(self.conv1x1(x))\n",
    "        out = torch.cat(conv_outs, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df5bb3cb-6d27-419f-8adf-868c2940b4c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = torch.rand(1, 16, 64, 64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7042df6f-12df-41f6-a525-f43a7e90bfc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dilation = 4\n",
    "a = nn.Conv3d(in_channels=16, out_channels=32, kernel_size=3,\n",
    "              stride=1, padding=dilation, dilation=dilation, padding_mode='replicate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29e7069a-5e98-4525-8ab4-0d2affa0cec2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 64, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "print(a(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2a8ea62-e9e3-415b-8316-2ebdf632eb68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6246, 0.2117, 0.7655, 0.1520],\n",
       "         [0.1736, 0.6900, 0.5929, 0.9164],\n",
       "         [0.9780, 0.6391, 0.5725, 0.0958],\n",
       "         [0.6851, 0.3209, 0.6306, 0.8064]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1, 4, 4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce66c7cd-69de-46a9-aa77-90a2409fed30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.6900, 0.1736, 0.6900, 0.5929, 0.9164, 0.5929],\n",
      "         [0.2117, 0.6246, 0.2117, 0.7655, 0.1520, 0.7655],\n",
      "         [0.6900, 0.1736, 0.6900, 0.5929, 0.9164, 0.5929],\n",
      "         [0.6391, 0.9780, 0.6391, 0.5725, 0.0958, 0.5725],\n",
      "         [0.3209, 0.6851, 0.3209, 0.6306, 0.8064, 0.6306],\n",
      "         [0.6391, 0.9780, 0.6391, 0.5725, 0.0958, 0.5725]]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.nn.functional.pad(x, (1,1,1,1), mode='reflect'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "51366cf4-0c39-43ed-a988-0f832af3bdde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.6246, 0.6246, 0.2117, 0.7655, 0.1520, 0.1520],\n",
      "         [0.6246, 0.6246, 0.2117, 0.7655, 0.1520, 0.1520],\n",
      "         [0.1736, 0.1736, 0.6900, 0.5929, 0.9164, 0.9164],\n",
      "         [0.9780, 0.9780, 0.6391, 0.5725, 0.0958, 0.0958],\n",
      "         [0.6851, 0.6851, 0.3209, 0.6306, 0.8064, 0.8064],\n",
      "         [0.6851, 0.6851, 0.3209, 0.6306, 0.8064, 0.8064]]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.nn.functional.pad(x, (1,1,1,1), mode='replicate'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d7ca96a6-14a8-4fe3-9b04-b4bf9e04b951",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.1520, 0.6246, 0.2117, 0.7655, 0.1520, 0.6246],\n",
      "         [0.9164, 0.1736, 0.6900, 0.5929, 0.9164, 0.1736],\n",
      "         [0.0958, 0.9780, 0.6391, 0.5725, 0.0958, 0.9780],\n",
      "         [0.8064, 0.6851, 0.3209, 0.6306, 0.8064, 0.6851]]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.nn.functional.pad(x, (1,1,), mode='circular'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefa92c2-3e0c-4118-8e1b-9a4840e7d1f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3a23e28-832c-4944-b130-2f015d82e96a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_config(channel_coef=8, act_fn=torch.nn.PReLU()):\n",
    "    A = channel_coef\n",
    "    \n",
    "    block_11_settings = {\n",
    "    \"in_blocks\" : {\n",
    "        \"IN\" : nn.Identity(),\n",
    "        },    \n",
    "    \"backbone\" : conv_block(1, A, kernel_size=3, stride=1, padding=1, act_fn=act_fn), \n",
    "    }\n",
    "\n",
    "    block_12_settings = {\n",
    "        \"in_blocks\" : {\n",
    "            \"b21\" : nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True),\n",
    "            \"b11\" : nn.Identity(),\n",
    "            },\n",
    "        \"backbone\" : conv_block(3*A, A, kernel_size=3, stride=1, padding=1, act_fn=act_fn), \n",
    "    }\n",
    "\n",
    "    block_13_settings = {\n",
    "        \"in_blocks\" : {\n",
    "            \"b22\" : nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True),\n",
    "            \"b12\" : nn.Identity(),\n",
    "            },\n",
    "        \"backbone\" : conv_block(3*A, A, kernel_size=3, stride=1, padding=1, act_fn=act_fn), \n",
    "    }\n",
    "\n",
    "    block_14_settings = {\n",
    "        \"in_blocks\" : {\n",
    "            \"b23\" : nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True),\n",
    "            \"b13\" : nn.Identity(),\n",
    "            },\n",
    "        \"backbone\" : conv_block(3*A, A, kernel_size=3, stride=1, padding=1, act_fn=act_fn), \n",
    "    }\n",
    "    \n",
    "    block_15_settings = {\n",
    "        \"in_blocks\" : {\n",
    "            \"b24\" : nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True),\n",
    "            \"b14\" : nn.Identity(),\n",
    "            },\n",
    "        \"backbone\" : conv_block(3*A, A, kernel_size=3, stride=1, padding=1, act_fn=act_fn), \n",
    "    }\n",
    "\n",
    "    block_21_settings = {\n",
    "        \"in_blocks\" : {\n",
    "            \"b11\" : nn.MaxPool3d(2, 2),\n",
    "            },\n",
    "        \"backbone\" : conv_block(A, 2*A, kernel_size=3, stride=1, padding=1, act_fn=act_fn), \n",
    "    }\n",
    "\n",
    "    block_22_settings = {\n",
    "        \"in_blocks\" : {\n",
    "            \"b31\" : nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True),\n",
    "            \"b21\" : nn.Identity(),\n",
    "            \"b12\" : nn.MaxPool3d(2, 2),\n",
    "            },\n",
    "        \"backbone\" : conv_block(7*A, 2*A, kernel_size=3, stride=1, padding=1, act_fn=act_fn), \n",
    "    }\n",
    "\n",
    "    block_23_settings = {\n",
    "        \"in_blocks\" : {\n",
    "            \"b32\" : nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True),\n",
    "            \"b22\" : nn.Identity(),\n",
    "            \"b13\" : nn.MaxPool3d(2, 2),\n",
    "            },\n",
    "        \"backbone\" : conv_block(7*A, 2*A, kernel_size=3, stride=1, padding=1, act_fn=act_fn), \n",
    "    }\n",
    "    \n",
    "    block_24_settings = {\n",
    "        \"in_blocks\" : {\n",
    "            \"b33\" : nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True),\n",
    "            \"b23\" : nn.Identity(),\n",
    "            \"b14\" : nn.MaxPool3d(2, 2),\n",
    "            },\n",
    "        \"backbone\" : conv_block(7*A, 2*A, kernel_size=3, stride=1, padding=1, act_fn=act_fn), \n",
    "    }\n",
    "\n",
    "    block_31_settings = {\n",
    "        \"in_blocks\" : {\n",
    "            \"b21\" : nn.MaxPool3d(2, 2),\n",
    "            },\n",
    "        \"backbone\" : conv_block(2*A, 4*A, kernel_size=3, stride=1, padding=1, act_fn=act_fn), \n",
    "    }\n",
    "\n",
    "    block_32_settings = {\n",
    "        \"in_blocks\" : {\n",
    "            \"b31\" : nn.Identity(),\n",
    "            \"b22\" : nn.MaxPool3d(2, 2),\n",
    "            \"b41\" : nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True),\n",
    "            },\n",
    "        \"backbone\" : conv_block(14*A, 4*A, kernel_size=3, stride=1, padding=1, act_fn=act_fn), \n",
    "    }\n",
    "    \n",
    "    block_33_settings = {\n",
    "        \"in_blocks\" : {\n",
    "            \"b32\" : nn.Identity(),\n",
    "            \"b23\" : nn.MaxPool3d(2, 2),\n",
    "            \"b42\" : nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True),\n",
    "            },\n",
    "        \"backbone\" : conv_block(14*A, 4*A, kernel_size=3, stride=1, padding=1, act_fn=act_fn), \n",
    "    }\n",
    "    \n",
    "    block_41_settings = {\n",
    "        \"in_blocks\" : {\n",
    "            \"b31\" : nn.MaxPool3d(2, 2),\n",
    "            },\n",
    "        \"backbone\" : conv_block(4*A, 8*A, kernel_size=3, stride=1, padding=1, act_fn=act_fn), \n",
    "    }\n",
    "    \n",
    "    block_42_settings = {\n",
    "        \"in_blocks\" : {\n",
    "            \"b41\" : bottle_neck_connection(8*A, 8*A, 16*A, act_fn=act_fn),\n",
    "            \"b32\" : nn.MaxPool3d(2, 2),\n",
    "            },\n",
    "        \"backbone\" : conv_block(12*A, 8*A, kernel_size=3, stride=1, padding=1, act_fn=act_fn), \n",
    "    }\n",
    "\n",
    "    block_out1_settings = {\n",
    "         \"in_blocks\" : {\n",
    "            \"b14\" : nn.Identity(),\n",
    "            },\n",
    "        \"backbone\" : conv_block(A, 1, kernel_size=3, stride=1, padding=1, act_fn=nn.Sigmoid()),\n",
    "    }\n",
    "\n",
    "    block_out2_settings = {\n",
    "         \"in_blocks\" : {\n",
    "            \"b24\" : nn.Identity(),\n",
    "            },\n",
    "        \"backbone\" : conv_block(2*A, 1, kernel_size=3, stride=1, padding=1, act_fn=nn.Sigmoid()),\n",
    "    }\n",
    "\n",
    "\n",
    "    net_blocks = { \n",
    "        \"b11\" : LiquidNetBlock(block_11_settings),\n",
    "        \"b12\" : LiquidNetBlock(block_12_settings),\n",
    "        \"b13\" : LiquidNetBlock(block_13_settings),\n",
    "        \"b14\" : LiquidNetBlock(block_14_settings),\n",
    "        \"b15\" : LiquidNetBlock(block_15_settings),\n",
    "        \"b21\" : LiquidNetBlock(block_21_settings),\n",
    "        \"b22\" : LiquidNetBlock(block_22_settings),\n",
    "        \"b23\" : LiquidNetBlock(block_23_settings),\n",
    "        \"b24\" : LiquidNetBlock(block_24_settings),\n",
    "        \"b31\" : LiquidNetBlock(block_31_settings),\n",
    "        \"b32\" : LiquidNetBlock(block_32_settings),\n",
    "        \"b33\" : LiquidNetBlock(block_33_settings),\n",
    "        \"b41\" : LiquidNetBlock(block_41_settings),\n",
    "        \"b42\" : LiquidNetBlock(block_42_settings),\n",
    "        \"out1\" : LiquidNetBlock(block_out1_settings),\n",
    "        \"out2\" : LiquidNetBlock(block_out2_settings),\n",
    "    }\n",
    "    return(net_blocks, [\"out1\", \"out2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a337bf69-066e-4366-817a-95e5b673e15d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_total_params(model):\n",
    "    total_params = sum(\n",
    "    param.numel() for param in model.parameters()\n",
    "    )\n",
    "    return(total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62f1c70a-fd71-40ce-92b8-524b4af8e2e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_params: 1327955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'IN': ['b11'],\n",
       " 'b11': ['b21', 'b12'],\n",
       " 'b21': ['b31', 'b12', 'b22'],\n",
       " 'b31': ['b41', 'b22', 'b32'],\n",
       " 'b12': ['b22', 'b13'],\n",
       " 'b22': ['b32', 'b13', 'b23'],\n",
       " 'b41': ['b32', 'b42'],\n",
       " 'b32': ['b42', 'b23', 'b33'],\n",
       " 'b13': ['b23', 'b14'],\n",
       " 'b23': ['b33', 'b14', 'b24'],\n",
       " 'b42': ['b33'],\n",
       " 'b33': ['b24'],\n",
       " 'b14': ['b24', 'out1', 'b15'],\n",
       " 'b24': ['out2', 'b15']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LiquidNet(*get_config(), debug=False)\n",
    "print(\"total_params:\", get_total_params(model))\n",
    "model.net_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f72fa48-abe5-4d69-9c18-4783847121cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 64, 64, 64])\n",
      "torch.Size([1, 1, 32, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "o = model(torch.rand(1, 1, 64, 64, 64))\n",
    "for out in o:\n",
    "    print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f411cf-0e93-40e5-9c84-3c7cff7b4a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a65ced8c-88eb-4f6b-a053-48aabea5981a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.to('cuda')\n",
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2152aab-df69-48b9-a800-7d6ae91086d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "n_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3df793ab-4132-46ff-a887-3026ab0f5ee4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = torch.rand(4, 1, 64, 64, 64)\n",
    "GT = torch.rand(4, 1, 64, 64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02f6469c-ad1e-4621-a38d-456e92b988ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m GT_cuda \u001b[38;5;241m=\u001b[39m GT\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m out \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward(x_cuda)   \n\u001b[0;32m----> 7\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGT_cuda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     10\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:536\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py:3284\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, target):\n\u001b[1;32m   3281\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   3282\u001b[0m         mse_loss, (\u001b[38;5;28minput\u001b[39m, target), \u001b[38;5;28minput\u001b[39m, target, size_average\u001b[38;5;241m=\u001b[39msize_average, reduce\u001b[38;5;241m=\u001b[39mreduce, reduction\u001b[38;5;241m=\u001b[39mreduction\n\u001b[1;32m   3283\u001b[0m     )\n\u001b[0;32m-> 3284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()):\n\u001b[1;32m   3285\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   3286\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a target size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) that is different to the input size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3287\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis will likely lead to incorrect results due to broadcasting. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3288\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure they have the same size.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(target\u001b[38;5;241m.\u001b[39msize(), \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()),\n\u001b[1;32m   3289\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   3290\u001b[0m     )\n\u001b[1;32m   3291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "model = model.to('cuda')\n",
    "for epoch in range(n_epochs):\n",
    "    x_cuda = x.to('cuda')\n",
    "    GT_cuda = GT.to('cuda')\n",
    "    \n",
    "    out = model.forward(x_cuda)   \n",
    "    loss = loss_fn(GT_cuda, out)\n",
    "\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    if epoch%10==0:\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bd882a-a8ea-41ed-82c8-1cd76565e1ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1913da07-c22e-45e0-bb0b-277431ac9e39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e135c90-5bd8-4113-92ee-4e51ea9a7842",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c42eccc-26ee-463c-87e7-03960d174214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6277ff17-54b5-4c2b-a976-7a27b16d6c71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bce35a-96f8-47b1-8660-ec14ea357588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d44a4d4-46de-4545-9bc0-97ee3e41f854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdae86e5-c021-4797-924b-32fa5cb22fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d71731d-0858-4489-bf23-ce1d91dd3d17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6704beb3-e2e8-4a30-855a-aaba9c3c5cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b2ba0b-1e19-45a9-be97-d1767f4984f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b13000f-ffaf-456c-be1d-d4370dd09de0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
