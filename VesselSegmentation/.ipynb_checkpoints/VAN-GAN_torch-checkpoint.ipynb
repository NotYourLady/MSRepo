{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfb60e2-530b-44b5-b405-6612c9a242fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca927d08-41ab-4877-b2bf-5b6b35f3ec0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "import torchio as tio\n",
    "\n",
    "from ml.models.ResUnet import ResUNet\n",
    "from ml.models.unet_deepsup import Unet_MSS\n",
    "\n",
    "from ml.models.building_blocks import VG_discriminator\n",
    "from ml.extra_libraries.CycleGAN_losses import (CycleLoss, ReconstructionLoss, SegmentationLoss,\n",
    "                                       DiscriminatorLoss, GeneratorLoss)\n",
    "from ml.losses import IOU_Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51c5f680-e578-4d83-b409-00c0fc34bc55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ml.tio_dataset import TioDataset\n",
    "train_settings  = {\n",
    "    \"patch_shape\" : (64, 64, 32),\n",
    "    \"patches_per_volume\" : 32,\n",
    "    \"patches_queue_length\" : 512,\n",
    "    \"batch_size\" : 2,\n",
    "    \"num_workers\": 4,\n",
    "    \"sampler\": \"weighted\" #\"uniform\",#\n",
    "}\n",
    "\n",
    "# val_settings  = {\n",
    "#     \"patch_shape\" : (32, 32, 32),\n",
    "#     \"patches_per_volume\" : 32,\n",
    "#     \"patches_queue_length\" : 1440,\n",
    "#     \"batch_size\" : 8,\n",
    "#     \"num_workers\": 4,\n",
    "#     \"sampler\": \"uniform\",#\"weighted\" #\"uniform\",#\n",
    "# }\n",
    "\n",
    "test_settings  = {\n",
    "    \"patch_shape\" : (192, 192, 128),\n",
    "    \"overlap_shape\" : (24, 24, 16),\n",
    "    \"batch_size\" : 1,\n",
    "    \"num_workers\": 4,\n",
    "}\n",
    "\n",
    "data_dir = \"/home/msst/Documents/medtech/MainData\"\n",
    "dataset = TioDataset(data_dir,\n",
    "                 train_settings=train_settings,\n",
    "                 val_settings=None,\n",
    "                 test_settings=test_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38d96795-a380-4d68-a471-5e477e538212",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VanGan(nn.Module):\n",
    "    def __init__(self, modules):\n",
    "        super(VanGan, self).__init__()\n",
    "        self.gen_IS = modules['gen_IS']\n",
    "        self.gen_SI = modules['gen_SI']\n",
    "        self.disc_I = modules['disc_I']\n",
    "        self.disc_S = modules['disc_S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9688321b-f2e4-4942-bf69-f5a601345a02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modules = {\n",
    "    'gen_IS': ResUNet(channels_coef=8),\n",
    "    'gen_SI': ResUNet(channels_coef=8),\n",
    "    'disc_I': VG_discriminator(channels_coef=64),\n",
    "    'disc_S': VG_discriminator(channels_coef=64),\n",
    "}\n",
    "model = VanGan(modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0227bafa-9030-4f06-b7d9-84a60e40ce86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_None(tensor):\n",
    "    if torch.isnan(tensor).sum() > 0:\n",
    "        raise RuntimeError(\"None here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c45dc3c-3277-49cc-8218-52073ea75b5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VG_Controller:\n",
    "    def __init__(self, config: Dict):\n",
    "        self.config = config\n",
    "        self.device = config['device']\n",
    "        self.model = config[\"model\"]\n",
    "        \n",
    "        otimizers_settings = config[\"otimizers_settings\"]\n",
    "        self.gen_IS_opt = otimizers_settings['gen_IS_opt'](self.model.gen_IS)\n",
    "        self.gen_SI_opt = otimizers_settings['gen_SI_opt'](self.model.gen_SI)\n",
    "        self.disc_I_opt = otimizers_settings['disc_I_opt'](self.model.disc_I)\n",
    "        self.disc_S_opt = otimizers_settings['disc_S_opt'](self.model.disc_S)\n",
    "        \n",
    "        if config.get('sheduler_fn') is not None:\n",
    "            self.with_sheduler = True\n",
    "            self.gen_IS_sheduler = otimizers_settings['sheduler_fn'](self.gen_IS_opt)\n",
    "            self.gen_SI_sheduler = otimizers_settings['sheduler_fn'](self.gen_SI_opt)\n",
    "            self.disc_I_sheduler = otimizers_settings['sheduler_fn'](self.disc_I_opt)\n",
    "            self.disc_S_sheduler = otimizers_settings['sheduler_fn'](self.disc_S_opt)\n",
    "        else:\n",
    "            self.with_sheduler = False\n",
    "        \n",
    "        losses = config[\"losses\"]\n",
    "        self.cycle_loss_fn = losses[\"cycle_loss_fn\"]\n",
    "        self.reconstruction_loss_fn = losses[\"reconstruction_loss_fn\"]\n",
    "        self.segmentation_loss_fn = losses[\"segmentation_loss_fn\"]\n",
    "        self.discriminator_loss_fn = losses[\"discriminator_loss_fn\"]\n",
    "        self.generator_loss_fn = losses[\"generator_loss_fn\"]\n",
    "        self.cycle_lambda = losses[\"cycle_lambda\"]\n",
    "        self.identity_lambda = losses[\"identity_lambda\"]\n",
    "        \n",
    "        self.epoch = 0\n",
    "        self.history = None\n",
    "        \n",
    "        self.metric_fn = IOU_Metric()\n",
    "        \n",
    "        \n",
    "\n",
    "    def fit(self, dataset, n_epochs):\n",
    "        model = self.model.to(self.device)\n",
    "        if self.history is None:\n",
    "            self.history = {\n",
    "                'train': [],\n",
    "                'val': [],\n",
    "                \"test\": [],\n",
    "            }\n",
    "        \n",
    "        start_epoch = self.epoch\n",
    "        for epoch in range(start_epoch, start_epoch+n_epochs):\n",
    "            self.epoch += 1\n",
    "            print(f\"Epoch {epoch + 1}/{start_epoch+n_epochs}\")\n",
    "            \n",
    "            train_info = self.train_epoch(dataset.train_dataloader)\n",
    "            print(train_info)\n",
    "            self.history['train'].append(train_info)\n",
    "            \n",
    "            if dataset.test_dataloader is not None:\n",
    "                test_info = self.test_epoch(dataset.test_dataloader)\n",
    "                print(test_info)\n",
    "                self.history['test'].append(test_info)\n",
    "            \n",
    "            if self.with_sheduler:\n",
    "                self.gen_IS_sheduler.step()\n",
    "                self.gen_SI_sheduler.step()\n",
    "                self.disc_I_sheduler.step()\n",
    "                self.disc_S_sheduler.step()\n",
    "            \n",
    "        return self.model.eval()\n",
    "\n",
    "    \n",
    "    def train_epoch(self, train_dataloader):\n",
    "        self.model.train()\n",
    "        \n",
    "        gen_IS_losses = []\n",
    "        gen_SI_losses = []\n",
    "        disc_I_losses = []\n",
    "        disc_S_losses = []\n",
    "        segmentation_losses = []\n",
    "        reconstruction_losses = []\n",
    "        \n",
    "        for patches_batch in tqdm(train_dataloader):\n",
    "            real_I = patches_batch['head']['data'].float().to(self.device)  \n",
    "            real_S = patches_batch['vessels']['data'].float().to(self.device) \n",
    "            \n",
    "            check_None(real_I)\n",
    "            check_None(real_S)\n",
    "            \n",
    "            #Generator outputs\n",
    "            fake_S = self.model.gen_IS(real_I)\n",
    "            fake_I = self.model.gen_SI(real_S)\n",
    "            cycled_S = self.model.gen_IS(fake_I)\n",
    "            cycled_I = self.model.gen_SI(fake_S)\n",
    "\n",
    "            # Discriminator outputs         \n",
    "            disc_real_S = self.model.disc_S(real_S)\n",
    "            disc_fake_S = self.model.disc_S(fake_S)\n",
    "            disc_real_I = self.model.disc_I(real_I)\n",
    "            disc_fake_I = self.model.disc_I(fake_I)\n",
    "            \n",
    "            check_None(fake_S)\n",
    "            check_None(fake_I)\n",
    "            check_None(cycled_S)\n",
    "            check_None(cycled_I)\n",
    "            check_None(disc_real_S)\n",
    "            check_None(disc_fake_S)\n",
    "            check_None(disc_real_I)\n",
    "            check_None(disc_fake_I)\n",
    "            \n",
    "            \n",
    "            #Losses\n",
    "            cycle_loss_I = self.cycle_loss_fn(real_S, cycled_S)\n",
    "            cycle_loss_S = self.cycle_loss_fn(real_I, cycled_I)\n",
    "            \n",
    "            segmentation_loss = self.segmentation_loss_fn(real_S, cycled_S)\n",
    "            reconstruction_loss = self.reconstruction_loss_fn(real_I, cycled_I)\n",
    "\n",
    "            gen_IS_loss = self.generator_loss_fn(disc_fake_S)\n",
    "            gen_SI_loss = self.generator_loss_fn(disc_fake_I)\n",
    "\n",
    "            total_loss_I = gen_IS_loss + self.cycle_lambda * cycle_loss_I +\\\n",
    "                           self.identity_lambda * segmentation_loss\n",
    "            total_loss_S = gen_SI_loss + self.cycle_lambda * cycle_loss_S +\\\n",
    "                           self.identity_lambda * reconstruction_loss  # + id_IS_loss\n",
    "            \n",
    "            \n",
    "            # -----------------\n",
    "            # Generators\n",
    "            # -----------------\n",
    "            self.gen_IS_opt.zero_grad()\n",
    "            self.gen_SI_opt.zero_grad()\n",
    "            \n",
    "            total_loss_I.backward(retain_graph=True)\n",
    "            total_loss_S.backward(retain_graph=True)\n",
    "            \n",
    "            self.gen_IS_opt.step()\n",
    "            self.gen_SI_opt.step()\n",
    "            \n",
    "            # -----------------\n",
    "            # Discriminators\n",
    "            # -----------------\n",
    "            \n",
    "            self.disc_I_opt.zero_grad()\n",
    "            self.disc_S_opt.zero_grad()\n",
    "            \n",
    "            disc_I_loss = self.discriminator_loss_fn(disc_real_I, disc_fake_I)\n",
    "            disc_S_loss = self.discriminator_loss_fn(disc_real_S, disc_fake_S)\n",
    "            \n",
    "            disc_I_loss.backward(retain_graph=True)\n",
    "            disc_S_loss.backward()\n",
    "            \n",
    "            self.disc_I_opt.step()\n",
    "            self.disc_S_opt.step()\n",
    "            \n",
    "            gen_IS_losses.append(gen_IS_loss.item())\n",
    "            gen_SI_losses.append(gen_SI_loss.item())\n",
    "            disc_I_losses.append(disc_I_loss.item())\n",
    "            disc_S_losses.append(disc_S_loss.item())\n",
    "            segmentation_losses.append(segmentation_loss.item())\n",
    "            reconstruction_losses.append(reconstruction_loss.item())\n",
    "        \n",
    "        self.model.eval()\n",
    "        out = {'gen_IS_loss': sum(gen_IS_losses)/len(gen_IS_losses),\n",
    "                'gen_SI_loss': sum(gen_SI_losses)/len(gen_SI_losses),\n",
    "                'disc_I_loss': sum(disc_I_losses)/len(disc_I_losses),\n",
    "                'disc_S_loss': sum(disc_S_losses)/len(disc_S_losses),\n",
    "                'segmentation_loss': sum(segmentation_losses)/len(segmentation_losses),\n",
    "                'reconstruction_loss': sum(reconstruction_losses)/len(reconstruction_losses),\n",
    "               }\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    def test_epoch(self, test_dataloader):\n",
    "        self.model.eval()\n",
    "        metrics = []\n",
    "        for batch in tqdm(test_dataloader):\n",
    "            patch_loader = batch[\"patch_loader\"]\n",
    "            grid_aggregator = batch[\"grid_aggregator\"]\n",
    "            GT = batch[\"GT\"]\n",
    "            sample_name = batch[\"sample_name\"]\n",
    "            head_seg = self.fast_predict(patch_loader, grid_aggregator)\n",
    "            metric = self.metric_fn(GT.data, head_seg)\n",
    "            metrics.append({\"sample\" : sample_name,\n",
    "                            \"seg_sum/GT_sum\" : head_seg.sum()/GT.data.sum()+0.000001,\n",
    "                            \"metric1\" : metric})\n",
    "            \n",
    "        return {'metrics': metrics}\n",
    "    \n",
    "    def fast_predict(self, patch_loader, grid_aggregator, thresh=0.5):\n",
    "        for patches_batch in patch_loader:\n",
    "            patch_locations = patches_batch[tio.LOCATION]\n",
    "            head_patches = patches_batch['head']['data'].to(self.device)\n",
    "            with torch.no_grad():\n",
    "                patch_seg = self.model.gen_IS(head_patches)\n",
    "                grid_aggregator.add_batch(patch_seg.cpu(), patch_locations)\n",
    "        seg = grid_aggregator.get_output_tensor()\n",
    "        seg[seg<thresh]=0\n",
    "        seg[seg>0]=1\n",
    "        return(seg)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7984aaad-a181-479d-bde8-4fab2871e7ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\"device\": \"cuda\",\n",
    "          \"otimizers_settings\":{\n",
    "            \"gen_IS_opt\" : lambda model: torch.optim.Adam(model.parameters(), lr=5e-2, betas=(0.5, 0.9)),\n",
    "            \"gen_SI_opt\" : lambda model: torch.optim.Adam(model.parameters(), lr=5e-2, betas=(0.5, 0.9)),\n",
    "            \"disc_I_opt\" : lambda model: torch.optim.Adam(model.parameters(), lr=2e-3, betas=(0.5, 0.9)),\n",
    "            \"disc_S_opt\" : lambda model: torch.optim.Adam(model.parameters(), lr=2e-3, betas=(0.5, 0.9)),\n",
    "            \"sheduler_fn\": lambda optimizer: ExponentialLR(optimizer, 0.98)\n",
    "            },\n",
    "          \"model\": model,\n",
    "          \"losses\":{\n",
    "            \"cycle_loss_fn\": CycleLoss(),\n",
    "            \"reconstruction_loss_fn\": ReconstructionLoss(),\n",
    "            \"segmentation_loss_fn\": SegmentationLoss(),\n",
    "            \"discriminator_loss_fn\": DiscriminatorLoss(),\n",
    "            \"generator_loss_fn\": GeneratorLoss(),\n",
    "            \"cycle_lambda\" : 10, \n",
    "            \"identity_lambda\" : 5,\n",
    "            }\n",
    "          }\n",
    "vg_controller = VG_Controller(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66dc9e86-55cd-45cd-8162-92a28f3d46dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 64/64 [00:36<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gen_IS_loss': 0.2923352918587625, 'gen_SI_loss': 0.2953451885841787, 'disc_I_loss': 0.13579580781515688, 'disc_S_loss': 0.21238530334085226, 'segmentation_loss': 0.015306337736546993, 'reconstruction_loss': 0.03378802476237297}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:24<00:00, 12.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metrics': [{'sample': 'P62_CTA_0', 'seg_sum/GT_sum': tensor(194.4020), 'metric1': tensor([0.0051])}, {'sample': 'new_CTA_0', 'seg_sum/GT_sum': tensor(210.8595), 'metric1': tensor([0.0047])}]}\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 64/64 [00:38<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gen_IS_loss': 0.3649800890125334, 'gen_SI_loss': 0.5539629943668842, 'disc_I_loss': 0.04123399007949047, 'disc_S_loss': 0.14607500151032582, 'segmentation_loss': 0.0, 'reconstruction_loss': 0.017128313956163765}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:23<00:00, 11.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metrics': [{'sample': 'P62_CTA_0', 'seg_sum/GT_sum': tensor(194.4020), 'metric1': tensor([0.0051])}, {'sample': 'new_CTA_0', 'seg_sum/GT_sum': tensor(210.8595), 'metric1': tensor([0.0047])}]}\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 64/64 [00:37<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gen_IS_loss': 0.5056046452373266, 'gen_SI_loss': 0.8282253611832857, 'disc_I_loss': 0.007073982458678074, 'disc_S_loss': 0.13542151456931606, 'segmentation_loss': 0.0, 'reconstruction_loss': 0.02023580162460803}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:23<00:00, 11.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metrics': [{'sample': 'P62_CTA_0', 'seg_sum/GT_sum': tensor(194.4020), 'metric1': tensor([0.0051])}, {'sample': 'new_CTA_0', 'seg_sum/GT_sum': tensor(210.8595), 'metric1': tensor([0.0047])}]}\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 64/64 [00:37<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gen_IS_loss': 0.512560420203954, 'gen_SI_loss': 0.905830075033009, 'disc_I_loss': 0.0018229260113002965, 'disc_S_loss': 0.14924840751336887, 'segmentation_loss': 0.0, 'reconstruction_loss': 0.025686402682225662}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:23<00:00, 11.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metrics': [{'sample': 'P62_CTA_0', 'seg_sum/GT_sum': tensor(194.4020), 'metric1': tensor([0.0051])}, {'sample': 'new_CTA_0', 'seg_sum/GT_sum': tensor(210.8595), 'metric1': tensor([0.0047])}]}\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 64/64 [00:37<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gen_IS_loss': 0.5143529488705099, 'gen_SI_loss': 0.934304446913302, 'disc_I_loss': 0.0014057661892366013, 'disc_S_loss': 0.14690564398188144, 'segmentation_loss': 0.0, 'reconstruction_loss': 0.024561628453056983}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:23<00:00, 11.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metrics': [{'sample': 'P62_CTA_0', 'seg_sum/GT_sum': tensor(194.4020), 'metric1': tensor([0.0051])}, {'sample': 'new_CTA_0', 'seg_sum/GT_sum': tensor(210.8595), 'metric1': tensor([0.0047])}]}\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 64/64 [00:37<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gen_IS_loss': 0.49681749008595943, 'gen_SI_loss': 0.9650933062657714, 'disc_I_loss': 0.00023165656375567778, 'disc_S_loss': 0.13772882346529514, 'segmentation_loss': 0.0, 'reconstruction_loss': 0.016847658077779215}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:22<00:00, 11.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metrics': [{'sample': 'P62_CTA_0', 'seg_sum/GT_sum': tensor(194.4020), 'metric1': tensor([0.0051])}, {'sample': 'new_CTA_0', 'seg_sum/GT_sum': tensor(210.8595), 'metric1': tensor([0.0047])}]}\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 64/64 [00:37<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gen_IS_loss': 0.5187529241666198, 'gen_SI_loss': 0.9593536015599966, 'disc_I_loss': 0.00456753137564192, 'disc_S_loss': 0.14310877659590915, 'segmentation_loss': 0.0, 'reconstruction_loss': 0.027155279101805263}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/2 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mvg_controller\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 57\u001b[0m, in \u001b[0;36mVG_Controller.fit\u001b[0;34m(self, dataset, n_epochs)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(train_info)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39mtest_dataloader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     test_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mprint\u001b[39m(test_info)\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(test_info)\n",
      "Cell \u001b[0;32mIn[6], line 179\u001b[0m, in \u001b[0;36mVG_Controller.test_epoch\u001b[0;34m(self, test_dataloader)\u001b[0m\n\u001b[1;32m    177\u001b[0m GT \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGT\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    178\u001b[0m sample_name \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_name\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 179\u001b[0m head_seg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfast_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatch_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid_aggregator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric_fn(GT\u001b[38;5;241m.\u001b[39mdata, head_seg)\n\u001b[1;32m    181\u001b[0m metrics\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample\u001b[39m\u001b[38;5;124m\"\u001b[39m : sample_name,\n\u001b[1;32m    182\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseg_sum/GT_sum\u001b[39m\u001b[38;5;124m\"\u001b[39m : head_seg\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m/\u001b[39mGT\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m0.000001\u001b[39m,\n\u001b[1;32m    183\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric1\u001b[39m\u001b[38;5;124m\"\u001b[39m : metric})\n",
      "Cell \u001b[0;32mIn[6], line 192\u001b[0m, in \u001b[0;36mVG_Controller.fast_predict\u001b[0;34m(self, patch_loader, grid_aggregator, thresh)\u001b[0m\n\u001b[1;32m    190\u001b[0m     head_patches \u001b[38;5;241m=\u001b[39m patches_batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhead\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 192\u001b[0m         patch_seg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen_IS\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_patches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m         grid_aggregator\u001b[38;5;241m.\u001b[39madd_batch(patch_seg\u001b[38;5;241m.\u001b[39mcpu(), patch_locations)\n\u001b[1;32m    194\u001b[0m seg \u001b[38;5;241m=\u001b[39m grid_aggregator\u001b[38;5;241m.\u001b[39mget_output_tensor()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/repo/MSRepo/VesselSegmentation/ml/models/ResUnet.py:81\u001b[0m, in \u001b[0;36mResUNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     79\u001b[0m     x \u001b[38;5;241m=\u001b[39m dec_blok[\u001b[38;5;241m1\u001b[39m](x, skip_layers[\u001b[38;5;241m3\u001b[39m\u001b[38;5;241m-\u001b[39midx])\n\u001b[1;32m     80\u001b[0m     check_None(x)\n\u001b[0;32m---> 81\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mdec_blok\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     check_None(x)    \n\u001b[1;32m     83\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_block(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/repo/MSRepo/VesselSegmentation/ml/models/building_blocks.py:105\u001b[0m, in \u001b[0;36mresidual_block.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 105\u001b[0m     main \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     shortcut \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshortcut_conv(x)\n\u001b[1;32m    107\u001b[0m     out \u001b[38;5;241m=\u001b[39m main \u001b[38;5;241m+\u001b[39m shortcut\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/repo/MSRepo/VesselSegmentation/ml/models/building_blocks.py:45\u001b[0m, in \u001b[0;36mconv_block.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 45\u001b[0m     \u001b[43mcheck_None\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(x)\n\u001b[1;32m     47\u001b[0m     check_None(x)\n",
      "File \u001b[0;32m~/repo/MSRepo/VesselSegmentation/ml/models/building_blocks.py:6\u001b[0m, in \u001b[0;36mcheck_None\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_None\u001b[39m(tensor):\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(tensor)\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone here (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39misnan(tensor)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vg_controller.fit(dataset, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a2284f-9823-4531-a5c8-b8b61dab6a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9228a22-7d60-4fbb-8825-99d10b4417ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad70a80e-4371-405f-b1c3-5bbff4b4c17a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff4a875-cf8d-42e8-b10c-02fd7c16de0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ff25b8-9046-4af8-95a8-b0eba6f8e708",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
